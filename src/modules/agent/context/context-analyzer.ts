import { Injectable, Logger } from '@nestjs/common';
import { AiService } from '../../ai/ai.service';
import { LlmFallbackAnalyzerService } from './fallback-analyzer';

export interface ConversationContext {
  hasContext: boolean;
  lastRecipes: string[];
  userReferences: string[];
  conversationSummary: string;
}

export interface ConversationHistory {
  role: 'user' | 'assistant';
  content: string;
}

@Injectable()
export class ConversationContextService {
  private readonly logger = new Logger(ConversationContextService.name);

  constructor(
    private readonly aiService: AiService,
    private readonly llmFallbackAnalyzerService: LlmFallbackAnalyzerService
  ) {}

  /**
   * ğŸ§  ëŒ€í™” ë§¥ë½ ë¶„ì„ (LLM ê¸°ë°˜)
   */
  async analyzeContext(
    message: string,
    conversationHistory?: ConversationHistory[]
  ): Promise<ConversationContext> {
    const context: ConversationContext = {
      hasContext: false,
      lastRecipes: [],
      userReferences: [],
      conversationSummary: ''
    };

    if (!conversationHistory || conversationHistory.length === 0) {
      return context;
    }

    context.hasContext = true;
    this.logger.log(`ğŸ“š ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¶„ì„: ${conversationHistory.length}ê°œ ë©”ì‹œì§€`);

    // ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ ë¶„ì„ (ì„±ëŠ¥ìƒ ì´ìœ )
    const recentHistory = conversationHistory.slice(-6); // user-assistant ìŒìœ¼ë¡œ 3ì„¸íŠ¸
    
    try {
      // LLMì„ í†µí•œ ëŒ€í™” ë§¥ë½ ë¶„ì„ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)
      const contextAnalysisPrompt = `ë‹¹ì‹ ì€ ëŒ€í™” ë§¥ë½ì„ ì •í™•íˆ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ë‹¤ìŒ ëŒ€í™” íˆìŠ¤í† ë¦¬ì™€ í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•œ JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

=== ëŒ€í™” íˆìŠ¤í† ë¦¬ ===
${recentHistory.map(msg => `${msg.role}: ${msg.content}`).join('\n')}

=== í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ===
"${message}"

=== ì¶”ì¶œí•  ì •ë³´ ===
ë‹¤ìŒ 3ê°€ì§€ ì •ë³´ë¥¼ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. **lastRecipes** (ë°°ì—´): 
   - ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ìš”ë¦¬/ë ˆì‹œí”¼ ì´ë¦„ë“¤
   - ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ì¶”ì²œí–ˆê±°ë‚˜ ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ëª¨ë“  ìš”ë¦¬ëª… í¬í•¨
   - ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []

2. **userReferences** (ë°°ì—´):
   - í˜„ì¬ ë©”ì‹œì§€ì—ì„œ ì´ì „ ëŒ€í™”ë¥¼ ì°¸ì¡°í•˜ëŠ” ëª¨ë“  í‘œí˜„ë“¤
   - í¬í•¨í•  í‘œí˜„: "ê·¸ê±°", "ê·¸ê²ƒ", "ê·¸ëŸ°", "ë‹¤ë¥¸", "ë˜ ë‹¤ë¥¸", "ëŒ€ì‹ ", "ë§ê³ ", "ì—†ì–´ì„œ", "ì•ˆë¼ì„œ", "ëª»í•´ì„œ" ë“±
   - ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []

3. **conversationSummary** (ë¬¸ìì—´):
   - ëŒ€í™”ì˜ í•µì‹¬ ë§¥ë½ì„ 80ì ì´ë‚´ë¡œ ìš”ì•½
   - ì‚¬ìš©ìì˜ ìš”ì²­, ì œì•½ì‚¬í•­, ìƒí™©ì„ í¬í•¨
   - ë¹ˆ ë¬¸ìì—´ì´ë©´ ì•ˆë¨

=== ì‘ë‹µ ì˜ˆì‹œ ===
ì‹œë‚˜ë¦¬ì˜¤ 1 - ì¼ë°˜ì ì¸ ê²½ìš°:
{
  "lastRecipes": ["ì§€ì¤‘í•´ì‹ ì¹˜í‚¨ ì¼€ë°¥", "í† ë§ˆí†  íŒŒìŠ¤íƒ€"],
  "userReferences": ["ê·¸ê²ƒ", "ì—†ì–´ì„œ"],
  "conversationSummary": "ì‚¬ìš©ìê°€ ì¼€ë°¥ì„ ìš”ì²­í–ˆì§€ë§Œ ë„êµ¬ê°€ ë¶€ì¡±í•´ì„œ ëŒ€ì•ˆì„ ì°¾ê³ ìˆìŒ"
}

ì‹œë‚˜ë¦¬ì˜¤ 2 - ì²« ëŒ€í™”ì¸ ê²½ìš°:
{
  "lastRecipes": [],
  "userReferences": [],
  "conversationSummary": "ì‚¬ìš©ìê°€ ì²˜ìŒìœ¼ë¡œ íŒŒìŠ¤íƒ€ ë ˆì‹œí”¼ë¥¼ ìš”ì²­í•¨"
}

ì‹œë‚˜ë¦¬ì˜¤ 3 - ì°¸ì¡° í‘œí˜„ì´ ë§ì€ ê²½ìš°:
{
  "lastRecipes": ["ê¹€ì¹˜ì°Œê°œ", "ëœì¥ì°Œê°œ"],
  "userReferences": ["ê·¸ëŸ°", "ë§ê³ ", "ë‹¤ë¥¸"],
  "conversationSummary": "ì‚¬ìš©ìê°€ ì°Œê°œë¥˜ ëŒ€ì‹  ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ìš”ë¦¬ë¥¼ ì›í•¨"
}

=== ì¤‘ìš” ì§€ì¹¨ ===
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”
- ëª¨ë“  ë¬¸ìì—´ì€ ìŒë”°ì˜´í‘œë¡œ ê°ì‹¸ì„¸ìš”
- ë°°ì—´ì´ ë¹„ì–´ìˆìœ¼ë©´ []ë¡œ, ë¬¸ìì—´ì´ ë¹„ì–´ìˆìœ¼ë©´ ""ë¡œ í‘œì‹œí•˜ì„¸ìš”
- JSON ì™¸ì˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
- í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”

JSON ì‘ë‹µ:`;

      const llmResponse = await this.aiService.generateResponse(contextAnalysisPrompt, {
        temperature: 0.1
      });

      if (llmResponse) {
        try {
          // JSON ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±° (ë” robustí•œ íŒŒì‹±)
          let cleanedResponse = llmResponse.trim();
          
          // JSON ë¸”ë¡ ì¶”ì¶œ (```json ``` í˜•íƒœë¡œ ê°ì‹¸ì§„ ê²½ìš° ì²˜ë¦¬)
          const jsonMatch = cleanedResponse.match(/```(?:json)?\s*(\{[\s\S]*?\})\s*```/);
          if (jsonMatch && jsonMatch[1]) {
            cleanedResponse = jsonMatch[1];
          }
          
          // ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ì¤‘ê´„í˜¸ ì‚¬ì´ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
          const startIndex = cleanedResponse.indexOf('{');
          const lastIndex = cleanedResponse.lastIndexOf('}');
          if (startIndex !== -1 && lastIndex !== -1 && lastIndex > startIndex) {
            cleanedResponse = cleanedResponse.substring(startIndex, lastIndex + 1);
          }
          
          const parsed = JSON.parse(cleanedResponse);
          
          // íƒ€ì… ê²€ì¦ ë° ì•ˆì „í•œ í• ë‹¹
          context.lastRecipes = Array.isArray(parsed.lastRecipes) ? parsed.lastRecipes : [];
          context.userReferences = Array.isArray(parsed.userReferences) ? parsed.userReferences : [];
          context.conversationSummary = typeof parsed.conversationSummary === 'string' ? parsed.conversationSummary : '';
          
          this.logger.log('âœ… LLM ëŒ€í™” ë§¥ë½ ë¶„ì„ ì„±ê³µ');
        } catch (parseError) {
          const errorMessage = parseError instanceof Error ? parseError.message : String(parseError);
          this.logger.warn('LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨, í´ë°± ë¶„ì„ ìˆ˜í–‰:', errorMessage);
          
          // í´ë°±: LLM ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ì •ë³´ ì¶”ì¶œ
          await this.performLlmFallbackAnalysis(message, recentHistory, context);
        }
      } else {
        this.logger.warn('LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŒ, í´ë°± ë¶„ì„ ìˆ˜í–‰');
        await this.performLlmFallbackAnalysis(message, recentHistory, context);
      }
    } catch (llmError) {
      this.logger.warn('LLM ëŒ€í™” ë§¥ë½ ë¶„ì„ ì‹¤íŒ¨:', llmError);
      // í´ë°±: ê°„ë‹¨í•œ ìš”ì•½ë§Œ ìƒì„±
      if (recentHistory.length > 0) {
        const lastUserMsg = recentHistory.filter(m => m.role === 'user').pop();
        context.conversationSummary = `ìµœê·¼ ì‚¬ìš©ì ìš”ì²­: ${lastUserMsg?.content?.substring(0, 50) || ''}`;
      }
    }

    this.logger.log(`ğŸ” ëŒ€í™” ë§¥ë½ - ì´ì „ ë ˆì‹œí”¼: [${context.lastRecipes.join(', ')}], ì°¸ì¡°: [${context.userReferences.join(', ')}]`);
    return context;
  }

  /**
   * ğŸ§  LLM ê¸°ë°˜ í´ë°± ë¶„ì„ (í•˜ë“œì½”ë”©ëœ ì •ê·œì‹ íŒ¨í„´ ëŒ€ì²´)
   */
  private async performLlmFallbackAnalysis(
    message: string, 
    recentHistory: ConversationHistory[], 
    context: ConversationContext
  ): Promise<void> {
    try {
      this.logger.log('ğŸ§  LLM ê¸°ë°˜ í´ë°± ë¶„ì„ ìˆ˜í–‰ ì¤‘...');
      
      const fallbackResult = await this.llmFallbackAnalyzerService.analyzeFallback(message, recentHistory);
      
      // ê²°ê³¼ë¥¼ contextì— ì ìš©
      context.userReferences = fallbackResult.userReferences;
      context.lastRecipes = fallbackResult.lastRecipes;
      context.conversationSummary = fallbackResult.conversationSummary;
      
      this.logger.log(`ğŸ§  LLM í´ë°± ë¶„ì„ ì™„ë£Œ (${fallbackResult.method}) - ë ˆì‹œí”¼: ${context.lastRecipes.length}ê°œ, ì°¸ì¡°: ${context.userReferences.length}ê°œ, ì‹ ë¢°ë„: ${fallbackResult.confidence}`);
    } catch (error) {
      this.logger.warn('LLM í´ë°± ë¶„ì„ ì‹¤íŒ¨, ê¸°ë³¸ ìš”ì•½ë§Œ ìƒì„±:', error);
      
      // ìµœí›„ ìˆ˜ë‹¨: ë§¤ìš° ê°„ë‹¨í•œ ìš”ì•½ë§Œ ìƒì„±
      if (recentHistory.length > 0) {
        const lastUserMsg = recentHistory.filter(m => m.role === 'user').pop();
        context.conversationSummary = `ì‚¬ìš©ì ìš”ì²­: ${lastUserMsg?.content?.substring(0, 50) || message.substring(0, 50)}`;
      } else {
        context.conversationSummary = `ìƒˆë¡œìš´ ëŒ€í™”: ${message.substring(0, 50)}`;
      }
      
      context.userReferences = [];
      context.lastRecipes = [];
    }
  }
}