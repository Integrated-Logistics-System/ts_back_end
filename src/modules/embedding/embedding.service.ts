import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import axios, { AxiosResponse } from 'axios';

export interface EmbeddingRequest {
  text: string;
  model?: string;
}

export interface EmbeddingResponse {
  embedding: number[];
  dimensions: number;
  processingTime: number;
}

export interface BatchEmbeddingRequest {
  texts: string[];
  model?: string;
  batchSize?: number;
}

export interface BatchEmbeddingResponse {
  embeddings: Array<{
    text: string;
    embedding: number[];
    index: number;
  }>;
  totalProcessed: number;
  totalTime: number;
  averageTime: number;
}

@Injectable()
export class EmbeddingService {
  private readonly logger = new Logger(EmbeddingService.name);
  private readonly ollamaBaseUrl: string;
  private readonly defaultModel = 'nomic-embed-text';
  private readonly expectedDimensions = 384;
  private readonly maxRetries = 3;
  private readonly retryDelay = 1000; // 1ì´ˆ

  constructor(private readonly configService: ConfigService) {
    this.ollamaBaseUrl = this.configService.get<string>('OLLAMA_URL', 'http://localhost:11434');
    this.logger.log(`ğŸ¤– Embedding Service initialized with Ollama URL: ${this.ollamaBaseUrl}`);
  }

  /**
   * ë‹¨ì¼ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±
   */
  async generateEmbedding(request: EmbeddingRequest): Promise<EmbeddingResponse> {
    const startTime = Date.now();
    const model = request.model || this.defaultModel;
    
    this.logger.log(`ğŸ” Generating embedding for text: "${request.text.substring(0, 100)}..." using model: ${model}`);

    try {
      const response = await this.callOllamaEmbedding(request.text, model);
      const embedding = response.data.embedding;
      
      // ì°¨ì› ê²€ì¦
      this.validateEmbeddingDimensions(embedding, model);
      
      const processingTime = Date.now() - startTime;
      
      this.logger.log(`âœ… Embedding generated successfully. Dimensions: ${embedding.length}, Time: ${processingTime}ms`);
      
      return {
        embedding,
        dimensions: embedding.length,
        processingTime
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      this.logger.error(`âŒ Failed to generate embedding: ${errorMessage}`);
      throw new Error(`Embedding generation failed: ${errorMessage}`);
    }
  }

  /**
   * ë°°ì¹˜ ì„ë² ë”© ìƒì„± (ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬)
   */
  async generateBatchEmbeddings(request: BatchEmbeddingRequest): Promise<BatchEmbeddingResponse> {
    const startTime = Date.now();
    const model = request.model || this.defaultModel;
    const batchSize = request.batchSize || 10;
    
    this.logger.log(`ğŸ”„ Starting batch embedding generation for ${request.texts.length} texts, batch size: ${batchSize}`);

    const results: Array<{ text: string; embedding: number[]; index: number }> = [];
    const totalTexts = request.texts.length;
    
    try {
      // ë°°ì¹˜ë³„ë¡œ ì²˜ë¦¬
      for (let i = 0; i < totalTexts; i += batchSize) {
        const batch = request.texts.slice(i, i + batchSize);
        this.logger.log(`ğŸ“¦ Processing batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(totalTexts / batchSize)} (${batch.length} items)`);
        
        // ë°°ì¹˜ ë‚´ ë³‘ë ¬ ì²˜ë¦¬
        const batchPromises = batch.map(async (text, batchIndex) => {
          const globalIndex = i + batchIndex;
          try {
            const embeddingResponse = await this.generateEmbedding({ text, model });
            return {
              text,
              embedding: embeddingResponse.embedding,
              index: globalIndex
            };
          } catch (error) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            this.logger.error(`âŒ Failed to process item ${globalIndex}: ${errorMessage}`);
            // ì‹¤íŒ¨í•œ í•­ëª©ë„ ê²°ê³¼ì— í¬í•¨ (ë¹ˆ ë°°ì—´ë¡œ)
            return {
              text,
              embedding: [],
              index: globalIndex
            };
          }
        });

        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);
        
        // ì§„í–‰ë¥  ë¡œê¹…
        const progress = ((i + batch.length) / totalTexts * 100).toFixed(1);
        this.logger.log(`ğŸ“ˆ Progress: ${progress}% (${i + batch.length}/${totalTexts})`);
        
        // ë°°ì¹˜ ê°„ ëŒ€ê¸° (Ollama ì„œë²„ ë¶€í•˜ ë°©ì§€)
        if (i + batchSize < totalTexts) {
          await this.sleep(100);
        }
      }

      const totalTime = Date.now() - startTime;
      const averageTime = totalTime / results.length;
      const successCount = results.filter(r => r.embedding.length > 0).length;
      
      this.logger.log(`âœ… Batch embedding completed. Success: ${successCount}/${totalTexts}, Total time: ${totalTime}ms, Avg: ${averageTime.toFixed(2)}ms`);
      
      return {
        embeddings: results,
        totalProcessed: results.length,
        totalTime,
        averageTime
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      this.logger.error(`âŒ Batch embedding failed: ${errorMessage}`);
      throw new Error(`Batch embedding generation failed: ${errorMessage}`);
    }
  }

  /**
   * ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (ê²€ìƒ‰ìš©)
   */
  async embedQuery(query: string): Promise<number[]> {
    this.logger.log(`ğŸ” Generating query embedding: "${query}"`);
    
    const response = await this.generateEmbedding({ text: query });
    return response.embedding;
  }

  /**
   * ë¬¸ì„œ ì„ë² ë”© ìƒì„± (ì¸ë±ì‹±ìš©)
   */
  async embedDocument(document: string): Promise<number[]> {
    this.logger.log(`ğŸ“„ Generating document embedding (${document.length} chars)`);
    
    const response = await this.generateEmbedding({ text: document });
    return response.embedding;
  }

  /**
   * Ollama API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
   */
  private async callOllamaEmbedding(text: string, model: string): Promise<AxiosResponse<any>> {
    let lastError: Error | undefined;
    
    for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
      try {
        this.logger.debug(`ğŸ”„ Attempt ${attempt}/${this.maxRetries} for embedding generation`);
        
        const response = await axios.post(
          `${this.ollamaBaseUrl}/api/embeddings`,
          {
            model,
            prompt: text,
          },
          {
            timeout: 30000, // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
            headers: {
              'Content-Type': 'application/json',
            },
          }
        );

        return response;

      } catch (error) {
        lastError = error as Error;
        const errorMessage = error instanceof Error ? error.message : String(error);
        this.logger.warn(`âš ï¸ Attempt ${attempt} failed: ${errorMessage}`);
        
        if (attempt < this.maxRetries) {
          const delay = this.retryDelay * attempt; // ì§€ìˆ˜ ë°±ì˜¤í”„
          this.logger.log(`â³ Retrying in ${delay}ms...`);
          await this.sleep(delay);
        }
      }
    }

    const lastErrorMessage = lastError instanceof Error ? lastError.message : 'Unknown error';
    throw new Error(`All ${this.maxRetries} attempts failed. Last error: ${lastErrorMessage}`);
  }

  /**
   * ì„ë² ë”© ì°¨ì› ê²€ì¦
   */
  private validateEmbeddingDimensions(embedding: number[], model: string): void {
    if (!Array.isArray(embedding) || embedding.length === 0) {
      throw new Error('Invalid embedding: empty or non-array result');
    }

    if (model === this.defaultModel && embedding.length !== this.expectedDimensions) {
      this.logger.warn(
        `âš ï¸ Unexpected embedding dimensions: expected ${this.expectedDimensions}, got ${embedding.length} for model ${model}`
      );
    }

    // NaNì´ë‚˜ ë¬´í•œê°’ ê²€ì‚¬
    const hasInvalidValues = embedding.some(val => !isFinite(val));
    if (hasInvalidValues) {
      throw new Error('Invalid embedding: contains NaN or infinite values');
    }
  }

  /**
   * ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
   */
  async getHealthStatus(): Promise<{
    status: 'healthy' | 'unhealthy';
    ollamaConnection: boolean;
    defaultModel: string;
    expectedDimensions: number;
    lastChecked: string;
  }> {
    try {
      // ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
      const testEmbedding = await this.generateEmbedding({ 
        text: 'health check test' 
      });

      return {
        status: 'healthy',
        ollamaConnection: true,
        defaultModel: this.defaultModel,
        expectedDimensions: this.expectedDimensions,
        lastChecked: new Date().toISOString(),
      };

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      this.logger.error(`âŒ Health check failed: ${errorMessage}`);
      
      return {
        status: 'unhealthy',
        ollamaConnection: false,
        defaultModel: this.defaultModel,
        expectedDimensions: this.expectedDimensions,
        lastChecked: new Date().toISOString(),
      };
    }
  }

  /**
   * ìœ í‹¸ë¦¬í‹°: ì§€ì—° í•¨ìˆ˜
   */
  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * ì„ë² ë”© ìºì‹œ í‚¤ ìƒì„±
   */
  generateCacheKey(text: string, model: string = this.defaultModel): string {
    const textHash = Buffer.from(text).toString('base64').substring(0, 20);
    return `embedding:${model}:${textHash}`;
  }
}