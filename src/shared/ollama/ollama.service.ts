import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import axios from 'axios';

interface OllamaGenerateRequest {
  model: string;
  prompt: string;
  stream: boolean;
  options?: {
    temperature?: number;
    top_k?: number;
    top_p?: number;
    num_predict?: number;
  };
}

interface OllamaGenerateResponse {
  response: string;
  done: boolean;
  model: string;
  created_at: string;
  context?: number[];
  total_duration?: number;
  load_duration?: number;
  prompt_eval_count?: number;
  prompt_eval_duration?: number;
  eval_count?: number;
  eval_duration?: number;
}

@Injectable()
export class OllamaService {
  private readonly logger = new Logger(OllamaService.name);
  private readonly baseUrl: string;
  private readonly defaultModel: string;
  private readonly timeout: number;

  constructor(private configService: ConfigService) {
    this.baseUrl = this.configService.get('OLLAMA_URL') || 'http://192.168.0.111:11434';
    this.defaultModel = this.configService.get('OLLAMA_MODEL') || 'qwen2.5:0.5b';
    this.timeout = 30000; // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
    
    this.checkConnection();
  }

  async checkConnection(): Promise<void> {
    try {
      const isConnected = await this.ping();
      if (isConnected) {
        this.logger.log('âœ… Ollama ì—°ê²° ì„±ê³µ');
        await this.checkModels();
      } else {
        this.logger.error('âŒ Ollama ì—°ê²° ì‹¤íŒ¨');
      }
    } catch (error) {
      this.logger.error('Ollama ì´ˆê¸°í™” ì˜¤ë¥˜:', error.message);
    }
  }

  async checkModels(): Promise<void> {
    try {
      const models = await this.listModels();
      if (models.length > 0) {
        this.logger.log(`ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: ${models.map(m => m.name).join(', ')}`);
        
        // ê¸°ë³¸ ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        const hasDefaultModel = models.some(m => m.name.includes(this.defaultModel.split(':')[0]));
        if (!hasDefaultModel) {
          this.logger.warn(`âš ï¸ ê¸°ë³¸ ëª¨ë¸ (${this.defaultModel})ì´ ì—†ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.`);
        }
      } else {
        this.logger.warn('âš ï¸ ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.');
      }
    } catch (error) {
      this.logger.error('ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error.message);
    }
  }

  async generateResponse(
    prompt: string,
    model?: string,
    options?: {
      temperature?: number;
      maxTokens?: number;
      stream?: boolean;
    }
  ): Promise<string> {
    try {
      const requestModel = model || this.defaultModel;
      
      this.logger.debug(`ğŸ¤– AI ì‘ë‹µ ìƒì„± ì‹œì‘ [${requestModel}]`);
      this.logger.debug(`ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: ${prompt.length}ì`);

      const requestData: OllamaGenerateRequest = {
        model: requestModel,
        prompt: prompt.trim(),
        stream: false,
        options: {
          temperature: options?.temperature || 0.7,
          num_predict: options?.maxTokens || 500,
        }
      };

      const response = await axios.post<OllamaGenerateResponse>(
        `${this.baseUrl}/api/generate`,
        requestData,
        {
          timeout: this.timeout,
          headers: {
            'Content-Type': 'application/json',
          }
        }
      );

      if (response.data && response.data.response) {
        const generatedText = response.data.response.trim();
        this.logger.debug(`âœ… AI ì‘ë‹µ ìƒì„± ì™„ë£Œ: ${generatedText.length}ì`);
        return generatedText;
      }

      throw new Error('Ollama ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.');

    } catch (error) {
      this.logger.error('AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error.message);
      
      if (error.code === 'ECONNREFUSED') {
        throw new Error('Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.');
      }
      
      if (error.response?.status === 404) {
        throw new Error(`ëª¨ë¸ '${model || this.defaultModel}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`);
      }
      
      if (error.code === 'ECONNABORTED') {
        throw new Error('AI ì‘ë‹µ ìƒì„± ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.');
      }
      
      throw new Error(`AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`);
    }
  }

  async listModels(): Promise<Array<{ name: string; size: number; digest: string }>> {
    try {
      const response = await axios.get(`${this.baseUrl}/api/tags`, {
        timeout: 5000
      });

      if (response.data && response.data.models) {
        return response.data.models;
      }

      return [];
    } catch (error) {
      this.logger.error('ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', error.message);
      return [];
    }
  }

  async ping(): Promise<boolean> {
    try {
      const response = await axios.get(`${this.baseUrl}/api/tags`, {
        timeout: 5000
      });
      return response.status === 200;
    } catch (error) {
      this.logger.error('Ollama ping ì‹¤íŒ¨:', error.message);
      return false;
    }
  }

  async pullModel(modelName: string): Promise<boolean> {
    try {
      this.logger.log(`ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: ${modelName}`);
      
      const response = await axios.post(
        `${this.baseUrl}/api/pull`,
        { name: modelName },
        { timeout: 300000 } // 5ë¶„ íƒ€ì„ì•„ì›ƒ
      );

      this.logger.log(`âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: ${modelName}`);
      return true;
    } catch (error) {
      this.logger.error(`ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ [${modelName}]:`, error.message);
      return false;
    }
  }

  async deleteModel(modelName: string): Promise<boolean> {
    try {
      await axios.delete(`${this.baseUrl}/api/delete`, {
        data: { name: modelName },
        timeout: 10000
      });

      this.logger.log(`ğŸ—‘ï¸ ëª¨ë¸ ì‚­ì œ ì™„ë£Œ: ${modelName}`);
      return true;
    } catch (error) {
      this.logger.error(`ëª¨ë¸ ì‚­ì œ ì‹¤íŒ¨ [${modelName}]:`, error.message);
      return false;
    }
  }

  getDefaultModel(): string {
    return this.defaultModel;
  }

  getBaseUrl(): string {
    return this.baseUrl;
  }
}
