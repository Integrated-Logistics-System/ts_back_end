# ğŸ¤– AI Recipe Backend - Production Deployment
# HTTP ì „ìš© ë°°í¬ (SSL ì—†ìŒ)
version: '3.8'

services:
  # ë°±ì—”ë“œ API ì„œë²„
  backend:
    build: .
    image: smart-recipe-backend:latest
    container_name: ai-recipe-backend
    ports:
      - "8081:8081"  # API í¬íŠ¸
      - "8083:8083"  # WebSocket í¬íŠ¸
    environment:
      NODE_ENV: production
      PORT: 8081
      WEBSOCKET_PORT: 8083
    env_file:
      - .env.production
    volumes:
      # ë¡œê·¸ ë³¼ë¥¨
      - ./logs:/app/logs
    restart: unless-stopped
    depends_on:
      ollama:
        condition: service_started
    networks:
      - ai-recipe-network
    
    # í—¬ìŠ¤ì²´í¬
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/api/auth/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # ë¦¬ì†ŒìŠ¤ ì œí•œ
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Ollama ì„œë¹„ìŠ¤
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-service
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped
    networks:
      - ai-recipe-network


networks:
  ai-recipe-network:
    driver: bridge

volumes:
  ollama-data:

# ğŸ¯ ì‚¬ìš©ë²•:
# export GITHUB_REPOSITORY=your-org/repo-name  
# docker-compose up -d

# ğŸŒ ì ‘ì†:
# http://server-ip:8081/api - API ì—”ë“œí¬ì¸íŠ¸
# ws://server-ip:8083 - WebSocket ì—”ë“œí¬ì¸íŠ¸